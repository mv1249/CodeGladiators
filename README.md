# CodeGladiators
 
## Problem Statement

<div class="content-block-extra">
    <p></p>
    <div>Digital Advertising is changing at a rapid pace with a huge increase in digital audience. At the same time, the digital advertising success metric is shifting from audience volume (eg. Impression count) to conversions (eg. lead submissions) as the
        success metric. This requires higher transparency and control on the conversions.</div>
    <div><br></div>
    <div>Colombia, the digital advertising arm of Times Internet Limited has seen significant growth in its digital advertising inventory. It wants to ensure that in all its conversion-based campaigns, no unfair advantage is given to the publishers generating
        fake leads. </div>
    <div><br></div>
    <div><b>Your task is to segregate the test data between genuine and false conversions by identifying the maximum possible 
            leads generated by the malignant technique.</b></div>
    <div><br></div>
    <div><b><u>Note- </u></b></div>
    <div>Joining with Click log: </div>
    <div>
        <div>imprId (Click Log) and imprid_cr (Conversion Log - Test and Train Data)</div>
        <div><br></div>
        <div>
            (Use click log data for additional data required for identifying conversion fraud)</div>
        <div><br></div>
        <div><b>Essential Columns</b>
            < /div>
                <div>
                    <ul>
                        <li>client id: Advertiser ID</li>
                        <li>pubclient id: Publisher ID</li>
                        <li>clickIp: IP Address</li>
                        <li>clmbuser id : unique user id</li>
                        <li>
                            impr id: Unique Key for every served impression</li>
                        <li>site id: Publisher wesite</li>
                        <li>goal id: Conversion`s goal type identification id</li>
                        <li>
                            City id / State id / CountryDim id: Geo Details</li>
                        <li>browser id: browser used for accessing publisher on any device on web.</li>
                        <li>adslot id: slot id where advertisement is displayed on any site (unqiue for all sites)</li>
                        <li>crtd: timestamp of the action</li>
                        <li>itmclmb id: Image/Creative shown</li>
                        <li>
                            ispDimId: Internet Service Provider</li>
                        <li>devTypeDimId: Device Id</li>
                        <li>osVerDimId: OS Version</li>
                    </ul>
                </div>
        </div>
    </div>
</div>

## Download the Dataset from here
<h4>Data Set <a href="https://www.techgig.com/files/DataScienceFullData/326708/AllDataSet.zip" class="action-lnk">Download Data Set</a></h4>

## My Approach 

<ol>
  <liFirst Approach was to join all the necessary columns and form a single csv file which contains all the data in one file.</li>

  <li>Second as the Dataset was imbalanced, so we have to balance the dataset by using undersampling ,oversampling or Smote.</li>


  <li>After that it is the turn to perform Exploratory Data Analysis on the dataset, generating insights and facts</li>


  <li>After that we check Transformations of the columns and try to fit the data in a Gaussian Distribution using Various Techniques,</li>


  <li>After Transformations its time for Feature Selection followed by Model Building and Hyperparameter Tuning.</li>

  <li>Last step is to work on metrics and then choose the appropriate model</li>
  
  <li>Then I moved on Model building and Hyperparameter Tuning and Evaluation of Metrics and then Rechecking them with the FAST AI Model.</li>

</ol>

## Observations


After possibly fixing all the transformations,using the Box-cox Transformation,i moved for outlier Detection and Found Outliers in Two columns,
and the best possible way to fill in values of those outliers was by filling with the min-max startegy,here is the image corresponding to it,we can observe that
either Mode or Median is a better choice for filling in the outliers for the "Client ID" column

<p align = "center">
   <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/5.PNG">
</p>

After fixing all the transformations and outliers,i went for Modelling where i started with Ensemble Techniques,The First thing which i did was to get the value of 
`ccp_alpha`,a hyperparamter which helps in pruning the Decision Tree so that we can avoid Overfitting,I could have used Bagging Technique as well
Here is the Graph for the Training and Testing Curves,which state the nature of the Decision Tree Algorithm

<p align = "center">
   <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/2.PNG">
</p>

From the above graph we observe that if we set the ccp_alpha values in between [0.005,0.015] we will be getting a better version of the Decision Tree,here is one sample where
i have set the value of `ccp_alpha` to be 0.015 and this is the resulted tree,previously the tree was very huge and its depth was almost till 20 levels!,after pruning it reduced

<p align = "center">
   <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/3.PNG">
</p>

After this i moved on with Feature Selection Using the Mutual Information Gain and ExtraTrees Classifier and identified the features which gave me most information among
all the features,here is the feature contribution and its value

<p align = "center">
   <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/4.PNG">
</p>
 
## Final Overview of Model
 
 <p align = "center">
   <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/6.PNG">
</p>
 

 
## Results 

After selecting the best features,then i moved on for model Building and Hyperparameter Tuning and Then Predictive Modelling using `FAST AI`,here is the image of the 
`value_counts` of the `conversion_fraud` column
 
Here are the Performance of various Machine Learning Algorithms on which i trained my Data
 <p align = "center">
   <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/9.PNG">
</p>
 Random Forest Seems Great,but it was not,as it failed in predicting the test data may be due to OverFitting,I selected Decision Tree as the Model,as it gave 
 all the metrics in a Good Number.
 
  After noticing the performance of various models which i displayed above,i went on to try out with Neural Networks,and guess what Neural Network 
 Outlasted all of them,Neural Network if Regularised in a Proper Manner are the best Machine Learning Models,here is the network summary of my neural network
 
 <p align = "center">
   <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/12.PNG" >
</p>
 
 ## Accuracy(Left) and Loss(Right) Curves for Neural Network Training
 
  <p float="left">
    <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/10.PNG" width = "250" height = "250"/>
    <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/11.PNG" width = "250" height = "250"/> 
  </p>

   
 
 #### Initial Counts (Given In Training Data)
 
 <p align = "center">
   <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/7.PNG">
</p>
 
This was the initial Count of Conversion Frauds as per the given Data,now lets see how does the Model Predict on it,Training data had 966 Rows,where as Testing Data
 nealy 450 rows.
 
 #### Final Counts (Prediction Stage,Testing the Model on Testing Data)
 
 <p align = "center">
   <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/1.PNG">
</p>

Decision Tree Performed Well in comparision to others as we can by the plots,by comparining the initial plots and Final Plots.
 
#### Neural Network Preidctions
 
 Neural Network did a job of almost 88% accuracy in classifiying the people,If trained on more parameters with optimised regularisation,Neural Network Can Perform
 Even better than other models,after all if more data and more training samples are provided to Neural Net it performs the best ! :)
 
 <p align = "center">
   <img src="https://github.com/mv1249/CodeGladiators/blob/main/images/13.PNG">
</p>
 
 # Result
  
  ##### Decision Tree - 84.3%
 
  ##### Neural Network - 88%
 
 
## Libraries Used
 
 <code><img height="30" src="https://raw.githubusercontent.com/numpy/numpy/7e7f4adab814b223f7f917369a72757cd28b10cb/branding/icons/numpylogo.svg"></code>
<code><img height="30" src="https://raw.githubusercontent.com/pandas-dev/pandas/761bceb77d44aa63b71dda43ca46e8fd4b9d7422/web/pandas/static/img/pandas.svg"></code>
<code><img height="30" src="https://matplotlib.org/_static/logo2.svg"></code>
<code><img height="30" src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/1280px-Scikit_learn_logo_small.svg.png"></code>
 <code><img height="30" src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Tensorflow_logo.svg/1200px-Tensorflow_logo.svg.png"></code>
 
 
 


